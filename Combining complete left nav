#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from lxml import html
import requests
import pandas as pd
import numpy as np 
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup
from contextlib import suppress
from time import sleep
from random import randint
from time import time


#The excel file below contains brand name and link to that brand name store on Amazon

xlsx = pd.ExcelFile("/Users/sidharthjain/Downloads/sarah-susan sheet 2.xlsx")
xlsx
df = xlsx.parse("Sheet1")
links=df["URL"]
links1=links[0:100]
links1

links1=["https://www.amazon.com/s/ref=sr_nr_n_9/144-5051398-4712941?fst=as%3Aoff&rh=n%3A283155%2Ck%3Avalentine%27s+day&keywords=valentine%27s+day&ie=UTF8&qid=1545949191&rnid=2941120011"]
import requests
from lxml.html import fromstring

main_link=[]        
link=[]
cat_name=[]
tag_name=[]
sku_count_final=[]
links1

for index, j in enumerate(links1):
    with suppress(Exception):
       
        headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36)'}
        page = requests.get(j,headers=headers)
        print(index)
        
        contents = page.content 
        
        print(contents)
        soup = BeautifulSoup(contents, "lxml")
        soup.prettify()
        prod_title=soup.find_all('a',attrs={'class':'a-link-normal s-ref-text-link'})
        x=prod_title
        print(x)

#The above code will give all the left nav html text for the left nav
        
        for i in range(len(x)):
            f=x[i]
            m='https://www.amazon.com'+ f['href']
            print(m)
            page_new = requests.get(m,headers=headers)
            sleep(randint(10,15))
            
            contents_new = page_new.content 
            #print(contents)
            soup_new = BeautifulSoup(contents_new, "lxml")
            soup_new.prettify()
            sku_count_find=soup.find('span',attrs={'id':'s-result-count'})
            sku_count=sku_count_find.text
            print(sku_count)
            
            
            with suppress(Exception):
                p=f.find('h4',attrs={'class':'a-size-small a-spacing-top-mini a-color-base a-text-bold'})
                q=p.text
                r="h4"
            with suppress(Exception):
                p=f.find('span',attrs={'class':'a-size-small a-color-base'})
                q=p.text
                r="span"
     
            main_link.append(j)
            link.append(m)
            cat_name.append(q)
            tag_name.append(r)
            sku_count_final.append(sku_count)
           
            
print(link)
print(cat_name)                
print(tag_name)
print(cat_name)
print(main_link)

df1 = pd.DataFrame({'main_page_link':main_link, 'Link to page': link,'Cat/subcat name': cat_name,'cat or subcat':tag_name})
df1
import pandas as pd

writer = pd.ExcelWriter('amazon_valentines_day.xlsx', engine='xlsxwriter',options={'strings_to_urls': False})
df1.to_excel(writer, sheet_name='Sheet1')
writer.save()

import os
cwd = os.getcwd()
cwd
